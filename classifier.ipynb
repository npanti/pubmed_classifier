{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM_classification_student.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8JC4LYa8jjE"
      },
      "source": [
        "# Classification de texte en deep learning (LSTM et convolution) \n",
        "\n",
        "## But de la tâche \n",
        "\n",
        "A partir d'un dataset d'articles PUBMED, le but est de classifier les articles dans des catégories thématiques en fonction de leur titre. \n",
        "\n",
        "Après une phase de préprocessing du texte, nous entrainerons un modèle à base de convolutions, puis un modèle à base de réseau de neurones récurrents (LSTM) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAervZV0djbe"
      },
      "source": [
        "## Cloner le repo https://github.com/aneuraz/intro-keras.git"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjN4D9A9EGB3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cd05cc5-f932-43f7-a02b-ba7f969a3d89"
      },
      "source": [
        "!git clone https://github.com/aneuraz/intro-keras.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'intro-keras'...\n",
            "remote: Enumerating objects: 18, done.\u001b[K\n",
            "remote: Counting objects: 100% (18/18), done.\u001b[K\n",
            "remote: Compressing objects: 100% (16/16), done.\u001b[K\n",
            "remote: Total 18 (delta 5), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (18/18), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFIznPvCc6o_"
      },
      "source": [
        "## Import des libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TrZgMq4fReH"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import json \n",
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oq5LGnyzduPx"
      },
      "source": [
        "## Chargement des données\n",
        "\n",
        "Toutes les données chargées se situent dans le répertoire `/content/`.\n",
        "Les données sont dans un fichier JSON."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYQ5UeLqfnM5"
      },
      "source": [
        "with open('/content/intro-keras/ai_pub_samp.json','r') as f:\n",
        "  data = json.load(f)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_PoXhiLfyAD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09baf880-601f-4d93-a823-8b783d1bcb37"
      },
      "source": [
        "data[0]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Cat_2013': 'C',\n",
              " 'Cat_2014': 'C',\n",
              " 'Cat_2015': 'C',\n",
              " 'Cat_2016': 'C',\n",
              " 'Cat_2017': 'B',\n",
              " 'Disciplines': ['XQ'],\n",
              " 'ESSN': '1873-3557',\n",
              " 'IF_2013': '2.129',\n",
              " 'IF_2014': '2.353',\n",
              " 'IF_2015': '2.653',\n",
              " 'IF_2016': '2.536',\n",
              " 'IF_2017': '2.88',\n",
              " 'ISSN': '1386-1425',\n",
              " 'ISSN_online': '1873-3557',\n",
              " 'ISSN_print': '1386-1425',\n",
              " 'IsoAbbr': 'Spectrochim Acta A Mol Biomol Spectrosc',\n",
              " 'JrId': 20555,\n",
              " 'MedAbbr': 'Spectrochim Acta A Mol Biomol Spectrosc',\n",
              " 'NLMid': '9602533',\n",
              " 'Titre': 'Spectrochim Acta A Mol Biomol Spectrosc',\n",
              " 'abstract': 'In this research, ZnO nanoparticle loaded on activated carbon (ZnO-NPs-AC) was synthesized simply by a low cost and nontoxic procedure. The characterization and identification have been completed by different techniques such as SEM and XRD analysis. A three layer artificial neural network (ANN) model is applicable for accurate prediction of dye removal percentage from aqueous solution by ZnO-NRs-AC following conduction of 270 experimental data. The network was trained using the obtained experimental data at optimum pH with different ZnO-NRs-AC amount (0.005-0.015 g) and 5-40 mg/L of sunset yellow dye over contact time of 0.5-30 min. The ANN model was applied for prediction of the removal percentage of present systems with Levenberg-Marquardt algorithm (LMA), a linear transfer function (purelin) at output layer and a tangent sigmoid transfer function (tansig) in the hidden layer with 6 neurons. The minimum mean squared error (MSE) of 0.0008 and coefficient of determination (R(2)) of 0.998 were found for prediction and modeling of SY removal. The influence of parameters including adsorbent amount, initial dye concentration, pH and contact time on sunset yellow (SY) removal percentage were investigated and optimal experimental conditions were ascertained. Optimal conditions were set as follows: pH, 2.0; 10 min contact time; an adsorbent dose of 0.015 g. Equilibrium data fitted truly with the Langmuir model with maximum adsorption capacity of 142.85 mg/g for 0.005 g adsorbent. The adsorption of sunset yellow followed the pseudo-second-order rate equation.',\n",
              " 'authors': ['Maghsoudi, M',\n",
              "  'Ghaedi, M',\n",
              "  'Zinali, A',\n",
              "  'Ghaedi, A M',\n",
              "  'Habibi, M H'],\n",
              " 'categories': ['SPECTROSCOPY'],\n",
              " 'journal': 'Spectrochimica acta. Part A, Molecular and biomolecular spectroscopy',\n",
              " 'keywords': ['Adsorption',\n",
              "  'Algorithms',\n",
              "  'Azo Compounds',\n",
              "  'Charcoal',\n",
              "  'Coloring Agents',\n",
              "  'Hydrogen-Ion Concentration',\n",
              "  'Kinetics',\n",
              "  'Microscopy, Electron, Scanning',\n",
              "  'Nanotubes',\n",
              "  'Neural Networks (Computer)',\n",
              "  'Time Factors',\n",
              "  'Water Pollutants, Chemical',\n",
              "  'X-Ray Diffraction',\n",
              "  'Zinc Oxide'],\n",
              " 'pmid': '24995412',\n",
              " 'title': 'Artificial neural network (ANN) method for modeling of sunset yellow dye adsorption using zinc oxide nanorods loaded on activated carbon: Kinetic and isotherm study.',\n",
              " 'year': '2015'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJrtCMBYeFvS"
      },
      "source": [
        "## TODO: Extraire les titres et les catégories"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MOQZkZxfzIy"
      },
      "source": [
        "# mettre le titre en minuscule dans la variable X\n",
        "X = [ x['title'].lower() for x in data ] \n",
        "\n",
        "# mettre la catégorie (1e élément de la liste) dans la variable Y\n",
        "Y = [ y['categories'][0] for y in data ] "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFN2trGeefrh"
      },
      "source": [
        "## TODO: Calculer la longueur maximale des titres dans le dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voXtnTBEgIXU"
      },
      "source": [
        "# longueur maximale des titres, variable max_len\n",
        "max_len = len(max(X, key=len))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iv9MBmJsexz9"
      },
      "source": [
        "## TODO: Diviser le dataset en train (X_train, Y_train) et test (X_test, Y_test)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIcFAOvDgz0L"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.2, random_state = 21)\n",
        "\n",
        "# X_train, Y_train\n",
        "X_train = X[:8000]\n",
        "Y_train = Y[:8000]\n",
        "\n",
        "# X_test, Y_test\n",
        "X_test = X[8000:]\n",
        "Y_test = Y[8000:]\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3DcNJBxggZW"
      },
      "source": [
        "## Transformer la variable Y en vecteur numerique\n",
        "\n",
        "[\"Cat 1\", \"Cat 2\"] -> [0, 1]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZ0dnsZuie3d"
      },
      "source": [
        "cat_to_id = {'<UNK>': 0}\n",
        "\n",
        "\n",
        "for t in Y_train:\n",
        "  if not t in cat_to_id.keys():\n",
        "    cat_to_id[t] = len(cat_to_id)\n",
        "\n",
        "id_to_cat = {v: k for k,v in cat_to_id.items()}\n",
        "\n",
        "\n",
        "# creer un mapping cat_2_id\n",
        "\n",
        "\n",
        "# creer un reverse mapping id_2_cat\n",
        "\n",
        "# calculer la taille du vocabulaire cat_vocab\n",
        "\n",
        "num_cat = len(cat_to_id)\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHLYjSWyigQ_"
      },
      "source": [
        "# preprocesser les X_train et X_test en X_train_id et X_test_id\n",
        "\n",
        "def preprocess_Y(Y, cat_to_id):\n",
        "  res = []\n",
        "  for ex in Y:\n",
        "    if ex not in cat_to_id.keys():\n",
        "      res.append(cat_to_id['<UNK>'])\n",
        "    else:\n",
        "      res.append(cat_to_id[ex])\n",
        "    \n",
        "  return np.array(res)\n",
        "\n",
        "Y_train_id = preprocess_Y(Y_train, cat_to_id)\n",
        "Y_test_id = preprocess_Y(Y_test, cat_to_id)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7I-bA1Dihtik"
      },
      "source": [
        "## Tokenizer les titres\n",
        "\n",
        "Pour cela vous pouvez utiliser la fonction `Tokenizer` de keras\n",
        "\n",
        "Le but est de transformer les textes en un vecteur numérique\n",
        "\n",
        "texte -> liste de tokens -> vecteur numérique\n",
        "\n",
        "\"Miaou le chat\" -> [\"Miaou\", \"le\", chat\"] -> [1, 2, 3]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-8LPBeJjJl8"
      },
      "source": [
        "# Créer le tokenizer\n",
        "vocab_size = 10000\n",
        "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words = vocab_size)\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07eGO99-j5ZX"
      },
      "source": [
        "# Entrainer le tokenizer sur le train set \n",
        "tokenizer.fit_on_texts(X_train)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nI6qhqplcKE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "93c55a3b-ee4b-4461-822b-4a5ffe523ffe"
      },
      "source": [
        "# Transformer les textes en vecteurs numeriques à l'aide du tokenizer\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "X_train[0]\n",
        "#X_train_seq[0]"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'artificial neural network (ann) method for modeling of sunset yellow dye adsorption using zinc oxide nanorods loaded on activated carbon: kinetic and isotherm study.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ao-Lj9nljVAH"
      },
      "source": [
        "## Faire un padding des sequences obtenues pour qu'elles aient toutes la même taille (cf la fonction `pad_sequences`)\n",
        "\n",
        "[1, 2, 3]       -> [0, 0, 1, 2 ,3]\n",
        "\n",
        "[4, 5, 6, 7, 8] -> [4, 5, 6, 7, 8]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aMIpV1clj8X"
      },
      "source": [
        "max_len = max([len(x) for x in X_train_seq])\n",
        "# Padding des sequences \n",
        "X_train_pad = tf.keras.preprocessing.sequence.pad_sequences(X_train_seq, maxlen=max_len, truncating='post')\n",
        "X_test_pad = tf.keras.preprocessing.sequence.pad_sequences(X_test_seq, maxlen=max_len, truncating='post')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZHz3Dljlk19",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bd60819-2444-4829-b628-c284b17d00a1"
      },
      "source": [
        "X_train_pad[0:5]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,   21,    9,   16,  945,   48,    4,   79,\n",
              "           1, 5677, 1973, 2247, 2614,    7, 2248, 2615, 5678, 3995,   13,\n",
              "        1586,  946, 1974,    2, 5679,   37],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,  462,    1,   74,  124,   48,    3,  615,\n",
              "         616, 3135,   10,    5,  693,   48],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,  135,   14,    1,  589,  143,\n",
              "         327,    3, 3136, 1337,   64, 2616],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,  802, 1587,    1, 5680, 1449, 3996,\n",
              "           2, 3137,   91,  220,   45,   65],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,  565,    1,\n",
              "        3138,  656,    4,  328,  765,    7,  307,  249,  484,   14,    3,\n",
              "        2617,  657,    2,  520,   26,   42]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMrlhsz_l-Pz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "623f3cf7-c955-4bc8-f637-e84d397fd570"
      },
      "source": [
        "X_test_pad[0:5]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,   23,   18, 3459, 9708,\n",
              "         197,  117,    3,    6,   85, 1354],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,   72,   89,    3,  911,  818,    3,    5, 1288,    1,\n",
              "         116,   14,    1,  255, 9110,  412],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,   46,   18,   23,  262,\n",
              "         142, 1309,    3,   19,  823,   33],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "         368,    2,  561,  384,  701,    1, 3827,  544,   11,   13,   45,\n",
              "          65, 1072,    3,   40,  696, 1313],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0, 1548,\n",
              "          99,   22,    5,  997,  179,  372]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkstuTOO05sw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e557850-a796-439b-8ee8-35f9b5192424"
      },
      "source": [
        "Y_test_id[0:100]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([29, 29, 10,  5,  5,  5,  6, 21, 21, 44, 21, 10, 20, 43,  6, 14, 55,\n",
              "        2,  7,  2, 12, 69, 10, 55, 10, 29, 10, 43, 30, 14, 78, 10,  5, 10,\n",
              "        3, 12,  5, 64, 48, 55, 11,  5,  5,  5,  5, 21, 85, 25, 10,  2, 11,\n",
              "       18, 10,  5, 20, 55,  6,  5, 10,  1, 45,  6,  2, 20, 12,  8,  2,  5,\n",
              "       18, 48,  1, 10, 26, 12, 70, 58, 12,  5, 12, 14,  2,  5,  5, 10, 21,\n",
              "        5, 12, 27,  7, 21,  5, 10,  5, 20,  5, 49, 45, 13, 16, 20])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KCGGWdoj_I2"
      },
      "source": [
        "# Réseau de convolution pour la classification de texte\n",
        "\n",
        "Les réseaux convolutionnels peuvent également être utiliser pour le texte et notamment pour la classification de texte. Ici nous allons construire un CNN sur le même modèle que pour les images avec quelques petites spécificités. \n",
        "\n",
        "Comme le texte est une séquence de mots, il s'agit d'une séquence en 1 dimension. Nous appliquerons donc une convolution en 1D. \n",
        "\n",
        "Pour traiter du texte, la première couche de notre réseau va être constituée par une couche d'embedding. \n",
        "\n",
        "Pour rappel, le word embedding consiste à projeter les tokens dans un espace vectoriel qui va minimiser la distance entre les tokens qui sont utilisés dans des contextes similaires (et qui ont un sens proche ? )\n",
        "\n",
        "![Texte alternatif…](https://www.ibm.com/blogs/research/wp-content/uploads/2018/10/WMEFig1.png)\n",
        "\n",
        "Les embeddings peuvent être calculés de diverses façons. Par exemple word2vec, un des plus célèbres, se base sur 2 algorithmes frères Skip-gram et CBOW\n",
        "\n",
        "![Texte alternatif…](https://pathmind.com/images/wiki/word2vec_diagrams.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQ-GICwamQGd"
      },
      "source": [
        "Pour information, il existe aujourd'hui des algorithmes plus performants que word2vec comme [Fasttext](https://fasttext.cc) qui prend en compte des informations de sous-mots ou la famille des embeddings contextuels comme [ELMo](https://allennlp.org/elmo) ou [BERT](https://arxiv.org/abs/1810.04805) qui prennent en compte le contexte d'utilisation du mot pour calculer son vecteur.\n",
        "\n",
        "> Bloc en retrait\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8L92Fw-TnUG4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cae5245-2f01-4ab4-908d-2f07e02fb639"
      },
      "source": [
        "embed_dim= 128\n",
        "dropout1 = 0.2\n",
        "conv_filters= 32\n",
        "conv_kernel = 2\n",
        "maxpool_size = 2\n",
        "dense_size = 128\n",
        "batch_size = 128\n",
        "epochs = 10\n",
        "\n",
        "model_cnn = tf.keras.models.Sequential()\n",
        "\n",
        "# Créer le modèle avec au minimum\n",
        "# Embedding \n",
        "model_cnn.add(tf.keras.layers.Embedding(vocab_size, \n",
        "                                        embed_dim, \n",
        "                                        input_length= max_len))\n",
        "\n",
        "# Dropout\n",
        "model_cnn.add(tf.keras.layers.Dropout(dropout1))\n",
        "\n",
        "# Convolution\n",
        "model_cnn.add(tf.keras.layers.Conv1D(conv_filters, conv_kernel, \n",
        "                                     padding='valid', \n",
        "                                     strides= 1, \n",
        "                                     activation='relu'))\n",
        "# Maxpooling\n",
        "model_cnn.add(tf.keras.layers.MaxPooling1D(maxpool_size))\n",
        "model_cnn.add(tf.keras.layers.Flatten())\n",
        "\n",
        "# Dense\n",
        "model_cnn.add(tf.keras.layers.Dense(dense_size,  activation='relu'))\n",
        "\n",
        "# Activation\n",
        "# Classifieur (Dense + activation softmax)\n",
        "model_cnn.add(tf.keras.layers.Dense(num_cat))\n",
        "model_cnn.add(tf.keras.layers.Activation('softmax'))\n",
        "\n",
        "# Compiler le modèle \n",
        "model_cnn.compile(loss='sparse_categorical_crossentropy', \n",
        "                  optimizer='adam', \n",
        "                  metrics= ['accuracy'])\n",
        "\n",
        "# Afficher le summary du modèle\n",
        "print(model_cnn.summary())"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 39, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 39, 128)           0         \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 38, 32)            8224      \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 19, 32)            0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 608)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               77952     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 97)                12513     \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 97)                0         \n",
            "=================================================================\n",
            "Total params: 1,378,689\n",
            "Trainable params: 1,378,689\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8TD5CkVnt-a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17cff773-c5e5-482c-96d0-fc0b352c557f"
      },
      "source": [
        "# Fitter le modèle \n",
        "model_cnn.fit(X_train_pad, Y_train_id, batch_size = batch_size , epochs = epochs)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "63/63 [==============================] - 1s 15ms/step - loss: 3.6857 - accuracy: 0.1844\n",
            "Epoch 2/10\n",
            "63/63 [==============================] - 1s 15ms/step - loss: 3.3163 - accuracy: 0.2216\n",
            "Epoch 3/10\n",
            "63/63 [==============================] - 1s 15ms/step - loss: 2.9923 - accuracy: 0.2829\n",
            "Epoch 4/10\n",
            "63/63 [==============================] - 1s 15ms/step - loss: 2.5880 - accuracy: 0.3792\n",
            "Epoch 5/10\n",
            "63/63 [==============================] - 1s 15ms/step - loss: 2.1363 - accuracy: 0.4745\n",
            "Epoch 6/10\n",
            "63/63 [==============================] - 1s 14ms/step - loss: 1.7061 - accuracy: 0.5907\n",
            "Epoch 7/10\n",
            "63/63 [==============================] - 1s 15ms/step - loss: 1.3387 - accuracy: 0.6771\n",
            "Epoch 8/10\n",
            "63/63 [==============================] - 1s 15ms/step - loss: 1.0453 - accuracy: 0.7554\n",
            "Epoch 9/10\n",
            "63/63 [==============================] - 1s 15ms/step - loss: 0.7999 - accuracy: 0.8154\n",
            "Epoch 10/10\n",
            "63/63 [==============================] - 1s 15ms/step - loss: 0.6134 - accuracy: 0.8655\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f97a0735d30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlAKERnqy-Wu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1aaae553-eb8d-4dd3-cf9a-1723e8a5dab3"
      },
      "source": [
        "# Evaluer le modèle\n",
        "model_cnn.evaluate(X_test_pad, Y_test_id)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "63/63 [==============================] - 0s 3ms/step - loss: 3.8217 - accuracy: 0.3120\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3.8216774463653564, 0.31200000643730164]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWqvNb5Jp1Uo"
      },
      "source": [
        "# LSTM pour la classification de texte\n",
        "\n",
        "Il est également possible d'utiliser un autre type de réseau de neurones pour effectuer ce genre de tâches: les réseaux de neurones récurrents ou RNN.\n",
        "\n",
        "Les RNN sont conçus pour gérer les séquences. Le réseau prend les tokens un par un et calcule une représentation de la séquence à chaque pas qui tiens compte de tous les pas précédents \n",
        "\n",
        "![Texte alternatif…](https://upload.wikimedia.org/wikipedia/commons/thumb/b/b5/Recurrent_neural_network_unfold.svg/450px-Recurrent_neural_network_unfold.svg.png)\n",
        "\n",
        "\n",
        "Il existe différents types de RNN. Ici nous utiliserons les Long Short-Term Memory (LSTM) qui permettent d'améliorer les performances sur des séquences longues avec une série de \"gates\". \n",
        "\n",
        "![Texte alternatif…](http://dprogrammer.org/wp-content/uploads/2019/04/RNN-vs-LSTM-vs-GRU-1200x361.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6mO7VTjocwk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3ca0adc-79d1-47ab-94d3-be6c2bf6d17c"
      },
      "source": [
        "lstm_size= 512\n",
        "dropout2= 0.2\n",
        "\n",
        "# Créer un réseau à base de LSTM avec au minimum:\n",
        "model_lstm = tf.keras.models.Sequential()\n",
        "# Embedding\n",
        "model_lstm.add(tf.keras.layers.Embedding(vocab_size, \n",
        "                                        embed_dim, \n",
        "                                        input_length= max_len))\n",
        "# Dropout\n",
        "model_lstm.add(tf.keras.layers.Dropout(dropout1))\n",
        "# LSTM\n",
        "model_lstm.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(lstm_size //2)))\n",
        "# Dropout\n",
        "model_lstm.add(tf.keras.layers.Dropout(dropout2))\n",
        "# Classifieur (Dense + activation softmax)\n",
        "model_lstm.add(tf.keras.layers.Dense(num_cat))\n",
        "model_lstm.add(tf.keras.layers.Activation('softmax'))\n",
        "\n",
        "\n",
        "\n",
        "# Compiler le modèle \n",
        "model_lstm.compile(loss='sparse_categorical_crossentropy', \n",
        "                  optimizer='adam', \n",
        "                  metrics= ['accuracy'])\n",
        "\n",
        "# Afficher le summary du modèle\n",
        "print(model_lstm.summary())\n",
        "\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 39, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 39, 128)           0         \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, 512)               788480    \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 97)                49761     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 97)                0         \n",
            "=================================================================\n",
            "Total params: 2,118,241\n",
            "Trainable params: 2,118,241\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VphlgAhjqSCD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d8e65dd-c3ed-49b4-a942-9217c51f6ee2"
      },
      "source": [
        "# Fitter le modèle\n",
        "model_lstm.fit(X_train_pad, Y_train_id, batch_size = batch_size , epochs = epochs)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "63/63 [==============================] - 2s 28ms/step - loss: 3.6067 - accuracy: 0.1831\n",
            "Epoch 2/10\n",
            "63/63 [==============================] - 2s 26ms/step - loss: 3.2601 - accuracy: 0.2375\n",
            "Epoch 3/10\n",
            "63/63 [==============================] - 2s 26ms/step - loss: 2.7702 - accuracy: 0.3173\n",
            "Epoch 4/10\n",
            "63/63 [==============================] - 2s 26ms/step - loss: 2.3720 - accuracy: 0.3915\n",
            "Epoch 5/10\n",
            "63/63 [==============================] - 2s 26ms/step - loss: 2.0231 - accuracy: 0.4773\n",
            "Epoch 6/10\n",
            "63/63 [==============================] - 2s 25ms/step - loss: 1.7230 - accuracy: 0.5533\n",
            "Epoch 7/10\n",
            "63/63 [==============================] - 2s 25ms/step - loss: 1.4743 - accuracy: 0.6093\n",
            "Epoch 8/10\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 1.2363 - accuracy: 0.6662\n",
            "Epoch 9/10\n",
            "63/63 [==============================] - 2s 25ms/step - loss: 1.0288 - accuracy: 0.7289\n",
            "Epoch 10/10\n",
            "63/63 [==============================] - 2s 25ms/step - loss: 0.8681 - accuracy: 0.7721\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f978c5b8d68>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVEY_kx3qSnS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "478ad307-7704-4c81-c682-d95f2a604def"
      },
      "source": [
        "# Evaluer le modèle\n",
        "model_lstm.evaluate(X_test_pad, Y_test_id)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "63/63 [==============================] - 0s 6ms/step - loss: 3.5024 - accuracy: 0.3250\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3.5024211406707764, 0.32499998807907104]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9x28y_mZsnbx"
      },
      "source": [
        "# Utiliser les embeddings pré-entrainés\n",
        "\n",
        "Pour améliorer la qualité de la représentation des mots, il est possible d'entrainer les embeddings sur de larges corpus de textes non annotés (typiquement Wikipedia). Ces modèles sont souvent disponibles en ligne et il est possible de les télécharger. Ici nous allons utiliser des embeddings [Glove](https://nlp.stanford.edu/projects/glove/) de taille 50d (pour des raisons techniques mais il vaut mieux utiliser des dimensions plus importantes entre 100 et 300) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXZjI4xX1xn7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17fd9970-eb0c-41f9-f41a-94dc9ae5627b"
      },
      "source": [
        "# Fonction permettant de charger un embedding \n",
        "\n",
        "import numpy as np\n",
        "import re\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "def load_glove_embeddings(fp, embedding_dim, include_empty_char=True):\n",
        "    \"\"\"\n",
        "    Loads pre-trained word embeddings (GloVe embeddings)\n",
        "        Inputs: - fp: filepath of pre-trained glove embeddings\n",
        "                - embedding_dim: dimension of each vector embedding\n",
        "                - generate_matrix: whether to generate an embedding matrix\n",
        "        Outputs:\n",
        "                - word2coefs: Dictionary. Word to its corresponding coefficients\n",
        "                - word2index: Dictionary. Word to word-index\n",
        "                - embedding_matrix: Embedding matrix for Keras Embedding layer\n",
        "    \"\"\"\n",
        "    # First, build the \"word2coefs\" and \"word2index\"\n",
        "    word2coefs = {} # word to its corresponding coefficients\n",
        "    word2index = {} # word to word-index\n",
        "    with open(fp) as f:\n",
        "        for idx, line in enumerate(f):\n",
        "            try:\n",
        "                data = [x.strip().lower() for x in line.split()]\n",
        "                word = data[0]\n",
        "                coefs = np.asarray(data[1:embedding_dim+1], dtype='float32')\n",
        "                word2coefs[word] = coefs\n",
        "                if word not in word2index:\n",
        "                    word2index[word] = len(word2index)\n",
        "            except Exception as e:\n",
        "                print('Exception occurred in `load_glove_embeddings`:', e)\n",
        "                continue\n",
        "        # End of for loop.\n",
        "    # End of with open\n",
        "    if include_empty_char:\n",
        "        word2index[''] = len(word2index)\n",
        "    # Second, build the \"embedding_matrix\"\n",
        "    # Words not found in embedding index will be all-zeros. Hence, the \"+1\".\n",
        "    vocab_size = len(word2coefs)+1 if include_empty_char else len(word2coefs)\n",
        "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "    for word, idx in word2index.items():\n",
        "        embedding_vec = word2coefs.get(word)\n",
        "        if embedding_vec is not None and embedding_vec.shape[0]==embedding_dim:\n",
        "            embedding_matrix[idx] = np.asarray(embedding_vec)\n",
        "    # return word2coefs, word2index, embedding_matrix\n",
        "    return word2index, np.asarray(embedding_matrix)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uiWQhLQ81yaA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e96c0b70-b53f-4787-fa38-084542b95247"
      },
      "source": [
        "# Télécharger les embeddings\n",
        "\n",
        "!wget https://github.com/kmr0877/IMDB-Sentiment-Classification-CBOW-Model/raw/master/glove.6B.50d.txt.gz\n",
        "!gunzip /content/glove.6B.50d.txt.gz"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-09 20:45:34--  https://github.com/kmr0877/IMDB-Sentiment-Classification-CBOW-Model/raw/master/glove.6B.50d.txt.gz\n",
            "Resolving github.com (github.com)... 192.30.255.113\n",
            "Connecting to github.com (github.com)|192.30.255.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/kmr0877/IMDB-Sentiment-Classification-CBOW-Model/master/glove.6B.50d.txt.gz [following]\n",
            "--2020-12-09 20:45:34--  https://raw.githubusercontent.com/kmr0877/IMDB-Sentiment-Classification-CBOW-Model/master/glove.6B.50d.txt.gz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 69182520 (66M) [application/octet-stream]\n",
            "Saving to: ‘glove.6B.50d.txt.gz’\n",
            "\n",
            "glove.6B.50d.txt.gz 100%[===================>]  65.98M   162MB/s    in 0.4s    \n",
            "\n",
            "2020-12-09 20:45:36 (162 MB/s) - ‘glove.6B.50d.txt.gz’ saved [69182520/69182520]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0CPaa_r3B3w"
      },
      "source": [
        "# Charger les embeddings à l'aide de la fonction load_glove_embeddings\n",
        "word2index, embedding_matrix = load_glove_embeddings('glove.6B.50d.txt', 50)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1T2Kdot3GKF"
      },
      "source": [
        "# ecrire une fonction de tokenization custom pour preprocesser les textes\n",
        "import re \n",
        "def custom_tokenizer(input, word2index):\n",
        "\n",
        "  # Split words\n",
        "  res = []\n",
        "  for t in input:\n",
        "    words = re.findall(r'\\w+', t)\n",
        "    index = []\n",
        "    for i in words:\n",
        "      if i in word2index.keys():\n",
        "        index.append(word2index[i])\n",
        "    res.append(index)\n",
        "\n",
        "  return res\n",
        "\n",
        "# Encoder les textes avec la fonction custom\n",
        "X_train_seq = custom_tokenizer(X_train, word2index)\n",
        "X_test_seq = custom_tokenizer(X_test, word2index)\n"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eF40dcAH4HEY"
      },
      "source": [
        "# Padding des sequences\n",
        "max_len = max([len(x) for x in X_train_seq])\n",
        "# Padding des sequences \n",
        "X_train_pad = tf.keras.preprocessing.sequence.pad_sequences(X_train_seq, maxlen=max_len, truncating='post')\n",
        "X_test_pad = tf.keras.preprocessing.sequence.pad_sequences(X_test_seq, maxlen=max_len, truncating='post')"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqxsq-rY527k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d15caccb-f86e-40e9-a2a1-156c76f837b1"
      },
      "source": [
        "# Créer un modèle en chargeant les poids des embeddings dans le layer Embedding\n",
        "lstm_size= 512\n",
        "dropout2= 0.2\n",
        "\n",
        "embed_dim= 50\n",
        "dropout1 = 0.2\n",
        "conv_filters= 32\n",
        "conv_kernel = 2\n",
        "maxpool_size = 2\n",
        "dense_size = 128\n",
        "\n",
        "# Créer un réseau à base de LSTM avec au minimum:\n",
        "model_lstm = tf.keras.models.Sequential()\n",
        "# Embedding\n",
        "model_lstm.add(tf.keras.layers.Embedding(400001, \n",
        "                                         embed_dim, \n",
        "                                         weights=[embedding_matrix], \n",
        "                                         input_length=max_len, \n",
        "                                         trainable=False))\n",
        "#model_lstm.add(tf.keras.layers.Embedding(vocab_size, \n",
        "#                                        embed_dim, \n",
        "#                                        input_length= max_len))\n",
        "# Dropout\n",
        "model_lstm.add(tf.keras.layers.Dropout(dropout1))\n",
        "# LSTM\n",
        "model_lstm.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(lstm_size //2)))\n",
        "# Dropout\n",
        "model_lstm.add(tf.keras.layers.Dropout(dropout2))\n",
        "# Classifieur (Dense + activation softmax)\n",
        "model_lstm.add(tf.keras.layers.Dense(num_cat))\n",
        "model_lstm.add(tf.keras.layers.Activation('softmax'))\n",
        "\n",
        "\n",
        "\n",
        "# Compiler le modèle \n",
        "model_lstm.compile(loss='sparse_categorical_crossentropy', \n",
        "                  optimizer='adam', \n",
        "                  metrics= ['accuracy'])\n",
        "\n",
        "# Afficher le summary du modèle\n",
        "print(model_lstm.summary())\n"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_9 (Embedding)      (None, 39, 50)            20000050  \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 39, 50)            0         \n",
            "_________________________________________________________________\n",
            "bidirectional_7 (Bidirection (None, 512)               628736    \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 97)                49761     \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 97)                0         \n",
            "=================================================================\n",
            "Total params: 20,678,547\n",
            "Trainable params: 678,497\n",
            "Non-trainable params: 20,000,050\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VTS-j-v6RLV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cd7b305-b0ad-4b0f-acff-f6ca8e8e3de0"
      },
      "source": [
        "# Fitter le modèle\n",
        "batch_size = 256\n",
        "epochs = 100\n",
        "model_lstm.fit(X_train_pad, Y_train_id, batch_size = batch_size , epochs = epochs)\n"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "63/63 [==============================] - 1s 15ms/step - loss: 3.4030 - accuracy: 0.2122\n",
            "Epoch 2/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 2.8736 - accuracy: 0.2864\n",
            "Epoch 3/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 2.6909 - accuracy: 0.3090\n",
            "Epoch 4/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 2.5670 - accuracy: 0.3293\n",
            "Epoch 5/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 2.4905 - accuracy: 0.3438\n",
            "Epoch 6/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 2.4197 - accuracy: 0.3531\n",
            "Epoch 7/100\n",
            "63/63 [==============================] - 1s 12ms/step - loss: 2.3449 - accuracy: 0.3661\n",
            "Epoch 8/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 2.2688 - accuracy: 0.3809\n",
            "Epoch 9/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 2.2165 - accuracy: 0.3931\n",
            "Epoch 10/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 2.1489 - accuracy: 0.4021\n",
            "Epoch 11/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 2.0872 - accuracy: 0.4170\n",
            "Epoch 12/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 2.0364 - accuracy: 0.4297\n",
            "Epoch 13/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 1.9875 - accuracy: 0.4333\n",
            "Epoch 14/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 1.9208 - accuracy: 0.4534\n",
            "Epoch 15/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 1.8559 - accuracy: 0.4631\n",
            "Epoch 16/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 1.8004 - accuracy: 0.4771\n",
            "Epoch 17/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 1.7363 - accuracy: 0.4901\n",
            "Epoch 18/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 1.6752 - accuracy: 0.5115\n",
            "Epoch 19/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 1.6317 - accuracy: 0.5188\n",
            "Epoch 20/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 1.5867 - accuracy: 0.5344\n",
            "Epoch 21/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 1.5113 - accuracy: 0.5515\n",
            "Epoch 22/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 1.4722 - accuracy: 0.5599\n",
            "Epoch 23/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 1.4048 - accuracy: 0.5825\n",
            "Epoch 24/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 1.3536 - accuracy: 0.5960\n",
            "Epoch 25/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 1.3077 - accuracy: 0.6076\n",
            "Epoch 26/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 1.2543 - accuracy: 0.6210\n",
            "Epoch 27/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 1.2316 - accuracy: 0.6295\n",
            "Epoch 28/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 1.1638 - accuracy: 0.6511\n",
            "Epoch 29/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 1.1175 - accuracy: 0.6634\n",
            "Epoch 30/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 1.0733 - accuracy: 0.6761\n",
            "Epoch 31/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 1.0542 - accuracy: 0.6779\n",
            "Epoch 32/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.9991 - accuracy: 0.7001\n",
            "Epoch 33/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.9709 - accuracy: 0.7107\n",
            "Epoch 34/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.9268 - accuracy: 0.7193\n",
            "Epoch 35/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.8908 - accuracy: 0.7281\n",
            "Epoch 36/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.8614 - accuracy: 0.7412\n",
            "Epoch 37/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.8245 - accuracy: 0.7530\n",
            "Epoch 38/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.8000 - accuracy: 0.7580\n",
            "Epoch 39/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.7612 - accuracy: 0.7785\n",
            "Epoch 40/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.7398 - accuracy: 0.7779\n",
            "Epoch 41/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.7208 - accuracy: 0.7804\n",
            "Epoch 42/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.7028 - accuracy: 0.7881\n",
            "Epoch 43/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.6570 - accuracy: 0.8040\n",
            "Epoch 44/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.6485 - accuracy: 0.8081\n",
            "Epoch 45/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.6133 - accuracy: 0.8221\n",
            "Epoch 46/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.5967 - accuracy: 0.8236\n",
            "Epoch 47/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.5865 - accuracy: 0.8259\n",
            "Epoch 48/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.5655 - accuracy: 0.8307\n",
            "Epoch 49/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.5346 - accuracy: 0.8419\n",
            "Epoch 50/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.5153 - accuracy: 0.8476\n",
            "Epoch 51/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.5064 - accuracy: 0.8540\n",
            "Epoch 52/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.4829 - accuracy: 0.8610\n",
            "Epoch 53/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.4699 - accuracy: 0.8634\n",
            "Epoch 54/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.4741 - accuracy: 0.8615\n",
            "Epoch 55/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.4491 - accuracy: 0.8689\n",
            "Epoch 56/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.4409 - accuracy: 0.8704\n",
            "Epoch 57/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.4233 - accuracy: 0.8786\n",
            "Epoch 58/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.4347 - accuracy: 0.8740\n",
            "Epoch 59/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.4108 - accuracy: 0.8841\n",
            "Epoch 60/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.4059 - accuracy: 0.8856\n",
            "Epoch 61/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.3730 - accuracy: 0.8920\n",
            "Epoch 62/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.3819 - accuracy: 0.8905\n",
            "Epoch 63/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.3659 - accuracy: 0.8930\n",
            "Epoch 64/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.3486 - accuracy: 0.9010\n",
            "Epoch 65/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.3470 - accuracy: 0.8985\n",
            "Epoch 66/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.3266 - accuracy: 0.9055\n",
            "Epoch 67/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.3225 - accuracy: 0.9106\n",
            "Epoch 68/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.3186 - accuracy: 0.9107\n",
            "Epoch 69/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.3055 - accuracy: 0.9118\n",
            "Epoch 70/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.3191 - accuracy: 0.9120\n",
            "Epoch 71/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.3027 - accuracy: 0.9135\n",
            "Epoch 72/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.2947 - accuracy: 0.9149\n",
            "Epoch 73/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.2912 - accuracy: 0.9150\n",
            "Epoch 74/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.2824 - accuracy: 0.9175\n",
            "Epoch 75/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.2905 - accuracy: 0.9162\n",
            "Epoch 76/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.2653 - accuracy: 0.9251\n",
            "Epoch 77/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.2776 - accuracy: 0.9189\n",
            "Epoch 78/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.2578 - accuracy: 0.9305\n",
            "Epoch 79/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.2516 - accuracy: 0.9300\n",
            "Epoch 80/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.2626 - accuracy: 0.9264\n",
            "Epoch 81/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.2591 - accuracy: 0.9255\n",
            "Epoch 82/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.2439 - accuracy: 0.9312\n",
            "Epoch 83/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.2458 - accuracy: 0.9299\n",
            "Epoch 84/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.2372 - accuracy: 0.9311\n",
            "Epoch 85/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.2297 - accuracy: 0.9367\n",
            "Epoch 86/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.2178 - accuracy: 0.9400\n",
            "Epoch 87/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.2330 - accuracy: 0.9344\n",
            "Epoch 88/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.2056 - accuracy: 0.9430\n",
            "Epoch 89/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.2140 - accuracy: 0.9389\n",
            "Epoch 90/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.2276 - accuracy: 0.9350\n",
            "Epoch 91/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.2066 - accuracy: 0.9430\n",
            "Epoch 92/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.1994 - accuracy: 0.9448\n",
            "Epoch 93/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.2098 - accuracy: 0.9394\n",
            "Epoch 94/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.2055 - accuracy: 0.9425\n",
            "Epoch 95/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.2049 - accuracy: 0.9409\n",
            "Epoch 96/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.1966 - accuracy: 0.9455\n",
            "Epoch 97/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.1871 - accuracy: 0.9484\n",
            "Epoch 98/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.1987 - accuracy: 0.9417\n",
            "Epoch 99/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.1981 - accuracy: 0.9456\n",
            "Epoch 100/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.2080 - accuracy: 0.9409\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f97108f26a0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikDrLZyC6b1c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc895fc7-1f91-46f6-994f-474c952dbddb"
      },
      "source": [
        "# evaluer le modèle\n",
        "model_lstm.evaluate(X_test_pad, Y_test_id)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "63/63 [==============================] - 0s 6ms/step - loss: 3.9401 - accuracy: 0.3345\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3.9401023387908936, 0.3345000147819519]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    }
  ]
}